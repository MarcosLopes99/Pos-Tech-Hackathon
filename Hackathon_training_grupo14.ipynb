{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **FIAP Pós-Tech - IA para Devs**"
      ],
      "metadata": {
        "id": "MEe8jee_I2Fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TURMA 1IADT - GRUPO 14 - ALUNOS"
      ],
      "metadata": {
        "id": "yEs9potaI3dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Marcelo Henriques da Fonseca - RM353865\n",
        "* Marcos Lopes da Silva Junior - RM353763\n",
        "* Ricardo Báfica Pontes - RM353866"
      ],
      "metadata": {
        "id": "Ud45O_lVI49v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HACKATHON"
      ],
      "metadata": {
        "id": "bAIv9F1hI7EG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DETECÇÃO DE MATERIAIS CORTANTES"
      ],
      "metadata": {
        "id": "hE-Mq90iI-4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A FIAP VisionGuard, empresa de monitoramento de câmeras de segurança, está\n",
        "analisando a viabilidade de uma nova funcionalidade para otimizar o seu software.\n",
        "\n",
        "O objetivo da empresa é usar de novas tecnologias para identificar situações atípicas e\n",
        "que possam colocar em risco a segurança de estabelecimentos e comércios que utilizam\n",
        "suas câmeras.\n",
        "\n",
        "Um dos principais desafios da empresa é utilizar Inteligência Artificial para identificar\n",
        "objetos cortantes (facas, tesouras e similares) e emitir alertas para a central de\n",
        "segurança.\n",
        "\n",
        "A empresa tem o objetivo de validar a viabilidade dessa feature, e para isso será\n",
        "necessário fazer um MVP para detecção supervisionada desses objetos.\n"
      ],
      "metadata": {
        "id": "_uYGJLyTJLDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBJETIVOS"
      ],
      "metadata": {
        "id": "z4dSm3bSJP6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Construir ou buscar um dataset contendo imagens de facas, tesouras e outros\n",
        "objetos cortantes em diferentes condições de ângulo e iluminação.\n",
        "*   Anotar o dataset para treinar o modelo supervisionado, incluindo imagens\n",
        "negativas (sem objetos perigosos) para reduzir falsos positivos.\n",
        "*   Treinar o modelo\n",
        "*   Desenvolver um sistema de alertas (pode ser e-mail)\n"
      ],
      "metadata": {
        "id": "U24FBDkOJZLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ENTREGÁVEL"
      ],
      "metadata": {
        "id": "OuCFJbGtJkED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Documentação detalhando o fluxo utilizado para o desenvolvimento da solução\n",
        "*   Vídeo de até 15 minutos explicando a solução proposta\n",
        "*   Link do github do projeto\n"
      ],
      "metadata": {
        "id": "9JFSHbZIJn_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TREINAMENTO"
      ],
      "metadata": {
        "id": "TCv-arLNJuok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste notebook, detalharemos o processo de montagem e acesso do dataset e realizaremos o treinamento do modelo que será utilizado para detecção de objetos cortantes."
      ],
      "metadata": {
        "id": "9JSkGADcRJF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar o Ultralytics e Roboflow\n",
        "!pip install ultralytics roboflow -q"
      ],
      "metadata": {
        "id": "QWkh9GX_J2lA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14b45e9-1f63-4abb-c1b4-23cae719efeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/913.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m911.4/913.5 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.5/913.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATASET"
      ],
      "metadata": {
        "id": "u0c8-19pFswq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De acordo com o objetivo da atividade, montamos um dataset com objetos cortantes para realização do treinamento do modelo.\n",
        "\n",
        "Esse dataset contém uma variedade de imagens de objetos cortantes, além de imagens negativas (sem objetos perigosos) e imagens de garfos e colheres, a fim de reduzir falsos positivos.\n",
        "\n",
        "Para a montagem do dataset, anotamos diversas imagens encontras online e também pegamos imagens já anotadas de outros datasets que encontramos.\n",
        "\n",
        "Ao todo, são 4821 imagens que serão utilizadas no treinamento do modelo.\n",
        "\n",
        "Por fim, decidimos usar o site Roboflow para fazer o controle dessas imagens."
      ],
      "metadata": {
        "id": "oQTT9wMuGehQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O dataset montado para realização do treinamento pode ser encontrado no seguinte link:\n",
        "\n",
        "https://app.roboflow.com/test-zeerx/knife_detection-roiuv"
      ],
      "metadata": {
        "id": "lJCLItbCF95j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets utilizados para a coletas de imagens anotadas:\n",
        "\n",
        "https://storage.googleapis.com/openimages/web/index.html\n",
        "\n",
        "https://datasetninja.com/od-weapon-detection-knife-detection\n",
        "\n",
        "https://www.kaggle.com/datasets/kilianovski/spoonvsfork\n",
        "\n",
        "https://universe.roboflow.com/dataset-pizme/axe-0eehv\n",
        "\n",
        "https://universe.roboflow.com/projetos-ifsul/axes-detection\n",
        "\n",
        "https://universe.roboflow.com/labelling-giajc/gun-knife-person\n",
        "\n",
        "https://universe.roboflow.com/pa-uzup9/guntingdetect"
      ],
      "metadata": {
        "id": "n5G0kuHwHpYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de começar o treinamento, nos conectaremos ao projeto hospedado no Roboflow a fim de baixar o dataset que será utilizado.\n",
        "\n",
        "Para isso, precisamos fazer uso de uma API KEY e apontar corretamente o projeto, a versão do dataset que será baixada e o formato, que nesse caso será \"yolov8\"."
      ],
      "metadata": {
        "id": "sMET9HO0Ibqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configurar chave da API Roboflow\n",
        "api_key = userdata.get('ROBOFLOW_API_KEY') # Chave armazenada no \"Secrets\" do Google Colab\n",
        "\n",
        "# Conectar ao projeto e baixar o dataset\n",
        "rf = Roboflow(api_key=api_key)\n",
        "project = rf.workspace(\"test-zeerx\").project(\"knife_detection-roiuv\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "id": "ASVI2ElAMj_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75945dcc-fc15-44bd-cbd1-bf1241dceb3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in knife_detection-3 to yolov8:: 100%|██████████| 252895/252895 [00:04<00:00, 61634.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to knife_detection-3 in yolov8:: 100%|██████████| 9648/9648 [00:01<00:00, 7121.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TREINANDO O MODELO"
      ],
      "metadata": {
        "id": "l08BRRqOFzi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este projeto decidimos fazer uso do [YoloV8](https://docs.ultralytics.com/models/yolov8/), um modelo da família YOLO para detecção de objetos em imagens e vídeos.\n",
        "\n",
        "O YoloV8 possui uma alta precisão, velocidade e facilidade de uso. Ele é amplamente utilizado em atividades que exigem detecção em tempo real, oque o torna ideal para este projeto que demanda um processamento rápido e eficiente."
      ],
      "metadata": {
        "id": "Tc3yMAeaKHS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dentre as versões disponíveis, optamos pelo \"YOLOv8m\", a versão de tamanho médio do modelo.\n",
        "\n",
        "Ela oferece que um bom equilíbrio entre velocidade de treinamento e precisão, nos permitindo gerar modelos de maneira não tão demorada mas ao mesmo tempo não compromendo a qualidade."
      ],
      "metadata": {
        "id": "ahIpDHQLLyxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o treinamento do nosso modelo, acessamos o arquivo data.yaml, que contém as configurações do dataset baixado localmente.\n",
        "\n",
        "Neste arquivo podemos encontrar os caminhos para os diretórios contendo as imagens e anotações e as classes serão reconhecidas, que nesse caso são:\n",
        "\n",
        "*   knife\n",
        "*   axe\n",
        "*   scissors\n",
        "*   fork\n",
        "*   spoon\n",
        "\n",
        "O principal objetivo desse projeto é a detecção de objetos cortantes, que seriam as classes \"knife\", \"axe\" e \"scissors\"."
      ],
      "metadata": {
        "id": "nZHzo-h3M5Sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também definimos alguns hiperparâmetros:\n",
        "\n",
        "**\"Epochs\":** define o número de épocas de treinamento. Uma época se refere a um ciclo que o modelo realizará processando o conjunto de treinamento.\n",
        "\n",
        "Um número maior de épocas pode melhorar melhorar o aprendizado e a precisão do modelo, mas também requer um tempo maior de treino e pode levar a overfitting (quando o modelo se ajusta tão bem ao conjunto de treinamento que ele perde precisão ao detectar imagens nunca vistas antes).\n",
        "\n",
        "**\"imgsz\":** tamanho das imagens utilizadas no treinamento.\n",
        "\n",
        "Um tamanho maior pode melhorar a precisão, especialmente para detecção de objetos pequenos, mas também requer um maior uso de memória e tempo de treinamento.\n",
        "\n",
        "**\"Batch\":** define o número de imagens processadas antes de atualizar os pesos do modelo.\n",
        "\n",
        "Um número maior pode ajudar a estabilizar o treinamento, mas requer mais memória.\n",
        "\n",
        "**\"Device\":** especifcia o dispositivo que será usado para o treinamento, CPU ou GPU."
      ],
      "metadata": {
        "id": "0WF8iuLCOhXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Carregar o modelo YOLO\n",
        "model = YOLO('yolov8m.pt')\n",
        "\n",
        "# Iniciar o treinamento\n",
        "model.train(\n",
        "    data='/content/knife_detection-3/data.yaml',  # Caminho do arquivo data.yaml\n",
        "    epochs=200,                         # Número de épocas\n",
        "    imgsz=640,                          # Tamanho das imagens\n",
        "    device=0                            # Use GPU (0 para a primeira GPU), 'cpu' para CPU\n",
        ")"
      ],
      "metadata": {
        "id": "4HuaOmkTNSJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao final do treinamento, exportamos o modelo e o armazenamos em uma pasta no Google Drive, que pode ser entrada no link a seguir. Esse ambiente também armazena vídeos que extraímos da internet para testar o modelo, assim como os outputs dos testes.\n",
        "\n",
        "https://drive.google.com/drive/folders/1t4HuKUUmmd-J29CkKJUHSI6jpNe_i49v?usp=sharing"
      ],
      "metadata": {
        "id": "DqXZwccZNEEZ"
      }
    }
  ]
}